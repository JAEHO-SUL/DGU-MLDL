{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivepath = Path(r'C:/Users/tjfwo/OneDrive/바탕 화면/GIT_Repository\\study\\Biosignals')\n",
    "datapath = drivepath / 'mitbih_data_split'\n",
    "datapath.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "df_train = pd.read_csv(datapath / 'mitbih_train.csv', header = None)\n",
    "df_test = pd.read_csv(datapath / 'mitbih_test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[187] = df_train[187].astype(int)\n",
    "label_count_train = df_train[187].value_counts()\n",
    "print(label_count_train)\n",
    "\n",
    "df_test[187] = df_test[187].astype(int)\n",
    "label_count_test = df_test[187].value_counts()\n",
    "print(label_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(label_count_train, labels=['N','Q','V','S','F'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(label_count_test, labels=['N','Q','V','S','F'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = df_train[187]\n",
    "target_test = df_test[187]\n",
    "\n",
    "y_train = target_train.values\n",
    "y_test = target_test.values\n",
    "\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "y_test = y_test.reshape(len(y_test),1)\n",
    "\n",
    "X_train = df_train.iloc[:, :-1].values\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1])\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = pd.DataFrame(columns=['Model', 'Accuracy (Train)', 'Precision (Train)', 'Recall (Train)', 'F1 Score (Train)', 'Accuracy (Test)', 'Precision (Test)', 'Recall (Test)', 'F1 Score (Test)','Training Time','Testing Time'])\n",
    "all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the SVM model\n",
    "svm = SVC(C=1.0, kernel='rbf', gamma='scale')\n",
    "\n",
    "# fit the model on the training data\n",
    "start_time = time.time()\n",
    "svm.fit(X_train_tensor, y_train_tensor)\n",
    "training_time = time.time() - start_time\n",
    "y_pred_svm_train = svm.predict(X_train_tensor)\n",
    "\n",
    "# make predictions on the test data\n",
    "start_time = time.time()\n",
    "y_pred_svm_test = svm.predict(X_test_tensor)\n",
    "testing_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix function\n",
    "class plot_score():\n",
    "    def plot_confusion_matrix(y_true, y_pred):\n",
    "        classes=['N', 'S', 'V', 'F', 'Q']\n",
    "        # Compute the confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap = plt.cm.Greens)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "            yticks=np.arange(cm.shape[0]),\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes,\n",
    "            xlabel='Predicted label',\n",
    "            ylabel='True label',\n",
    "            aspect='equal',\n",
    "            )\n",
    "        plt.xticks(np.arange(cm.shape[1]),  rotation=45, fontweight='bold', color='black',fontsize=10)\n",
    "        plt.yticks(np.arange(cm.shape[0]),  fontweight='bold', color='black',fontsize=10)\n",
    "        plt.ylabel('True label', fontweight='bold', color='black',fontsize=10)\n",
    "        plt.xlabel('Predicted label', fontweight='bold', color='black',fontsize=10)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                        ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                        color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def score_train(y_train, y_pred_train):\n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)*100\n",
    "        precision_train = precision_score(y_train, y_pred_train, average='macro')*100\n",
    "        recall_train = recall_score(y_train, y_pred_train, average='macro')*100\n",
    "        f1_train = f1_score(y_train, y_pred_train, average='macro')*100\n",
    "        print(\"Accuracy (Train): {:.4f}\".format(accuracy_train))\n",
    "        print(\"Precision (Train): {:.4f}\".format(precision_train))\n",
    "        print(\"Recall (Train): {:.4f}\".format(recall_train))\n",
    "        print(\"F1 score (Train): {:.4f}\".format(f1_train))\n",
    "        return accuracy_train, precision_train, recall_train, f1_train\n",
    "        \n",
    "    def score_test(y_test, y_pred):\n",
    "        accuracy_test = accuracy_score(y_test, y_pred)*100\n",
    "        precision_test = precision_score(y_test, y_pred, average='macro')*100\n",
    "        recall_test = recall_score(y_test, y_pred, average='macro')*100\n",
    "        f1_test = f1_score(y_test, y_pred, average='macro')*100\n",
    "        print(\"Accuracy (Test): {:.4f}\".format(accuracy_test))\n",
    "        print(\"Precision (Test): {:.4f}\".format(precision_test))\n",
    "        print(\"Recall (Test): {:.4f}\".format(recall_test))\n",
    "        print(\"F1 score (Test): {:.4f}\".format(f1_test))\n",
    "        return accuracy_test, precision_test, recall_test, f1_test\n",
    "\n",
    "#plot_and_score = plot_score()\n",
    "#plot_confusion_matrix_svm_train = plot_and_score.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_train, y_pred_svm_train)\n",
    "plot_score.plot_confusion_matrix(y_test, y_pred_svm_test)\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_train, y_pred_svm_train)\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test, y_pred_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='SVM'\n",
    "all_model.loc[0] = [model_name, accuracy_train, precision_train, recall_train, f1_train, accuracy_test, precision_test, recall_test, f1_test, training_time, testing_time]\n",
    "all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LR model\n",
    "lr = LogisticRegression(fit_intercept=True, solver='lbfgs', random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "start_time = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "y_pred_lr_train = lr.predict(X_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "start_time = time.time()\n",
    "y_pred_lr_test = lr.predict(X_test)\n",
    "testing_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_train, y_pred_lr_train)\n",
    "plot_score.plot_confusion_matrix(y_test, y_pred_lr_test)\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_train, y_pred_lr_train)\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test, y_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Logistic Regression'\n",
    "all_model.loc[1] = [model_name, accuracy_train, precision_train, recall_train, f1_train, accuracy_test, precision_test, recall_test, f1_test, training_time, testing_time]\n",
    "all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the DT model\n",
    "dt = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=10, random_state=0)\n",
    "\n",
    "# fit the model on the training data\n",
    "start_time = time.time()\n",
    "dt.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "y_pred_dt_train = dt.predict(X_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "start_time = time.time()\n",
    "y_pred_dt_test = dt.predict(X_test)\n",
    "testing_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_train, y_pred_dt_train)\n",
    "plot_score.plot_confusion_matrix(y_test, y_pred_dt_test)\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_train, y_pred_dt_train)\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test, y_pred_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Decision Tree'\n",
    "all_model.loc[2] = [model_name, accuracy_train, precision_train, recall_train, f1_train, accuracy_test, precision_test, recall_test, f1_test, training_time, testing_time]\n",
    "all_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞의 Classification model들의 파라미터에 대한 설정?\n",
    "- NN, MLP, CNN 모델 완성 및 학습해야됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_Linear\n",
    "hidden = nn.Linear(187, 300, bias=True)\n",
    "output = nn.Linear(300, 5, bias=True)\n",
    "\n",
    "model_nn = nn.Sequential(hidden, output)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_nn.parameters(), lr=0.01)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_train_tensor = y_train_tensor.flatten()\n",
    "\n",
    "history = []\n",
    "\n",
    "for step in range(10):\n",
    "    y_pred_nn_train = model_nn(X_train_tensor)\n",
    "    loss = loss_fn(y_pred_nn_train, y_train_tensor)\n",
    "    \n",
    "    history.append({\"step\": step, \"loss\": loss.item()})\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "y_test_tensor = y_test_tensor.flatten()\n",
    "\n",
    "history_test = []\n",
    "\n",
    "model_nn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_nn_test = model_nn(X_test_tensor)\n",
    "    loss = loss_fn(y_pred_nn_test, y_test_tensor)\n",
    "    history_test.append({\"step\": step, \"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_pred_nn_train.detach().numpy().argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_train_tensor, y_pred_nn_train.argmax(dim=1))\n",
    "plot_score.plot_confusion_matrix(y_test_tensor, y_pred_nn_test.argmax(dim=1))\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_train, y_pred_nn_train.detach().numpy().argmax(axis=1))\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test, y_pred_nn_test.detach().numpy().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_NonLinear\n",
    "hidden = nn.Linear(187, 300, bias=True)\n",
    "activation = nn.ReLU()\n",
    "output = nn.Linear(300, 5, bias=True)\n",
    "\n",
    "model_non = nn.Sequential(hidden, activation, output)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_non.parameters(), lr=0.01)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_train_tensor = y_train_tensor.flatten()\n",
    "\n",
    "history = []\n",
    "\n",
    "for step in range(10):\n",
    "    y_pred_non_train = model_non(X_train_tensor)\n",
    "    loss = loss_fn(y_pred_non_train, y_train_tensor)\n",
    "    \n",
    "    history.append({\"step\": step, \"loss\": loss.item()})\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "y_test_tensor = y_test_tensor.flatten()\n",
    "\n",
    "history_test = []\n",
    "\n",
    "model_non.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_non_test = model_non(X_test_tensor)\n",
    "    loss = loss_fn(y_pred_non_test, y_test_tensor)\n",
    "    history_test.append({\"step\": step, \"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_train_tensor, y_pred_non_train.argmax(dim=1))\n",
    "plot_score.plot_confusion_matrix(y_test_tensor, y_pred_non_test.argmax(dim=1))\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_train, y_pred_non_train.detach().numpy().argmax(axis=1))\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test, y_pred_non_test.detach().numpy().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "model_mlp = nn.Sequential(\n",
    "    nn.Linear(187,300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300,5),\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(model_mlp.parameters(), lr = 0.001)\n",
    "num_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "X_traintrain_tensor, X_trainval_tensor, y_traintrain_tensor, y_trainval_tensor = train_test_split(\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    test_size=0.5,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    stratify=y_train_tensor,\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_traintrain_tensor, y_traintrain_tensor)\n",
    "val_dataset = TensorDataset(X_trainval_tensor, y_trainval_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    model_mlp.train()\n",
    "    for batch in train_loader:\n",
    "        x, y_true = batch\n",
    "        y_logits_train = model_mlp(x)\n",
    "        \n",
    "        loss = loss_fn(y_logits_train, y_true)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_dataset)\n",
    "\n",
    "    model_mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, y_true = batch\n",
    "            y_logits_val = model_mlp(x)\n",
    "\n",
    "            loss = loss_fn(y_logits_val, y_true)\n",
    "            eval_loss += loss\n",
    "            \n",
    "    eval_loss /= len(val_dataset)\n",
    "    \n",
    "    history.append({\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss.item(),\n",
    "        'eval_loss': eval_loss.item(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).plot(x='epoch', y=['train_loss', 'eval_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y_true = batch\n",
    "        y_logits_test = model_mlp(x)\n",
    "        loss = loss_fn(y_logits_test, y_true)\n",
    "        test_loss += loss\n",
    "test_loss /= len(test_dataset)\n",
    "\n",
    "print(test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_mlp_train = model_mlp(X_traintrain_tensor)\n",
    "    y_pred_mlp_val = model_mlp(X_trainval_tensor)\n",
    "    y_pred_mlp_test = model_mlp(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score.plot_confusion_matrix(y_traintrain_tensor, y_pred_mlp_train.argmax(dim=1))\n",
    "plot_score.plot_confusion_matrix(y_trainval_tensor, y_pred_mlp_val.argmax(dim=1))\n",
    "plot_score.plot_confusion_matrix(y_test_tensor, y_pred_mlp_test.argmax(dim=1))\n",
    "accuracy_train, precision_train, recall_train, f1_train = plot_score.score_train(y_traintrain_tensor, y_pred_mlp_train.detach().numpy().argmax(axis=1))\n",
    "accuracy_val, precision_val, recall_val, f1_val = plot_score.score_train(y_trainval_tensor, y_pred_mlp_val.detach().numpy().argmax(axis=1))\n",
    "accuracy_test, precision_test, recall_test, f1_test = plot_score.score_test(y_test_tensor, y_pred_mlp_test.detach().numpy().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "            nn.Conv1d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(87*64, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 5)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(-1, 87*64)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cnn = CNN().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_batch = len(train_data) // batch_size\n",
    "\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "        X = batch_images.cuda()\n",
    "        Y = batch_labels.cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 300 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02\n",
    "x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "for model in models:\n",
    "    pre = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pre = pre.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, pre, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    plt.scatter(val_x[:, 0], val_x[:, 1], c=val_y, cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(model)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
